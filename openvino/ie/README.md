# Using the Intel OpenVINO Inference Engine

The Intel OpenVINO Inference Engine is a set of libraries for executing convolutional neural networks.

GoCV support for the Intel OpenVINO Inference Engine will be able to be found here in the "github.com/TokenUndefined/gocv/openvino/ie" package.

## Roadmap

Support in GoCV for the Intel OpenVINO Inference Engine is still under development, and is not yet in a usable state.

- [ ] InferenceEnginePlugin - work started, can load plugin
- [X] CNNNetReader
- [ ] CNNNetwork  - work started
- [ ] InputsDataMap
- [ ] InputInfo
- [ ] OutputsDataMap
- [ ] InferRequest
- [ ] Blob
